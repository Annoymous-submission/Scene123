<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title> Scene123: One Prompt to 3D Scene Generation via Video-Assisted and Consistency-Enhanced MAE </title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Scene123: One Prompt to 3D Scene Generation via Video-Assisted and Consistency-Enhanced MAE</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://yiyingyang12.github.io/yiyingyang.github.io/" target="_blank">Yiying Yang</a><sup>1*</sup>,</span>
                <span class="author-block">
                  <a href="https://fukunyin.github.io/" target="_blank">Fukun Yin</a><sup>1*</sup>,</span>
                  <span class="author-block">
                    <a target="_blank">Jiayuan Fan</a><sup>1†</sup>,</span>
                    <span class="author-block">
                      <a href="https://chenxin.tech/" target="_blank">Xin Chen</a><sup>2</sup>,</span>
                      <span class="author-block">
                         <a target="_blank">Wanzhang Li</a><sup>1</sup>,</span>
                          <span class="author-block">
                             <a href="https://www.skicyyu.org/" target="_blank">Gang Yu</a><sup>2</sup>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"> <sup>1</sup>Fudan University <sup>2</sup>Tencent PCG  </span> <br>
                    <span class="eql-cntrb"><small><sup>*</sup>Equal Contribution</small></span> <span class="eql-cntrb"><small><sup>†</sup>Corresponding author</small></span>

                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YiyingYang12/Scene123" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          As Artificial Intelligence Generated Content (AIGC) advances, a variety of methods have been developed to generate text, images, videos, and 3D objects from single or multimodal inputs, contributing efforts to emulate human-like cognitive content creation. However, generating realistic large-scale scenes from a single input presents a challenge due to the complexities involved in ensuring consistency across extrapolated views generated by models. Benefiting from recent video generation models and implicit neural representations, we propose Scene123, a 3D scene generation model, that not only ensures realism and diversity through the video generation framework but also uses implicit neural fields combined with Masked Autoencoders (MAE) to effectively ensures the consistency of unseen areas across views. Specifically, we initially warp the input image (or an image generated from text) to simulate adjacent views, filling the invisible areas with the MAE model. However, these filled images usually fail to maintain view consistency, thus we utilize the produced views to optimize a neural radiance field, enhancing geometric consistency. Moreover, to further enhance the details and texture fidelity of generated views, we employ a GAN-based Loss against images derived from the input image through the video generation model. Extensive experiments demonstrate that our method can generate realistic and consistent scenes from a single prompt. Both qualitative and quantitative results indicate that our approach surpasses existing state-of-the-art methods. 
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->



<!-- Single Image Display -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Pipeline</h2>
      <div class="item" style="text-align: center;">
        <!-- Your image here -->
        <img src="static/images/pipeline.png" alt="MY ALT TEXT" style="width: 100%; height: auto; max-width: 600px;"/>
        <h2 class="subtitle has-text-centered">
        Scene123's pipeline includes two key modules: the consistency-enhanced MAE and the 3D-aware generative refinement module. The former generates adjacent views from an input image via warping, using the MAE model to inpaint unseen areas with global semantics and optimizing an implicit neural field for viewpoint consistency. The latter generates realistic scene videos from the input image with a pre-trained video generation model, enhancing realism through adversarial loss with rendered images.
        </h2>
      </div>
    </div>
  </div>
</section>
<!-- End Single Image Display -->




<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title has-text-centered">Results</h2>
      <h3 class="subtitle has-text-centered">3D Scenes Generated from Diverse Prompts</h3>
      <div class="columns is-multiline is-mobile">
        <div class="column is-one-quarter">
          <figure class="image is-4by3">
            <video controls>
              <source src="static/videos/carouse1.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </figure>
          <p class="has-text-centered">a bedroom with a desk.</p>
        </div>
        <div class="column is-one-quarter">
          <figure class="image is-4by3">
            <video controls>
              <source src="static/videos/carouse2.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </figure>
          <p class="has-text-centered">a bedroom with a desk.</p>
        </div>
        <div class="column is-one-quarter">
          <figure class="image is-4by3">
            <video controls>
              <source src="static/videos/carouse3.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </figure>
          <p class="has-text-centered">a cozy living room.</p>
        </div>
        <div class="column is-one-quarter">
          <figure class="image is-4by3">
            <video controls>
              <source src="static/videos/carouse1.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </figure>
          <p class="has-text-centered">a cozy living room.</p>
        </div>
      </div>
    </div>
  </div>
</section>





<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
